{
  "certified_bentos": [
    {
      "org_name": "bentoml",
      "repo_name": "control_net",
      "description": {
        "name": "ControlNet",
        "text": "ControlNet is a type of model for controlling image diffusion models by conditioning the model with an additional input image. There are many types of conditioning inputs (canny edge, user sketching, human pose, depth, and more) you can use to control a diffusion model.",
        "link": "github.com/bentoml/BentoDiffusion/tree/main/controlnet",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/controlnet.jpeg",
        "label": [
          "üé® Image Generation"
        ]
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "stable_diffusion2",
      "description": {
        "name": "Stable Diffusion 2",
        "text": "Stable Diffusion is a deep learning, text-to-image model based on diffusion techniques. Stable Diffusion 2.0 delivers several big improvements and features including a new text-to-image diffusion models, super-resolution upscaler diffusion models, depth-to-image diffusion model, and updated inpainting diffusion model.",
        "link": "github.com/bentoml/BentoDiffusion/tree/main/sd2upscaler",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/stabilityai.png",
        "label": [
          "üé® Image Generation"
        ]
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "whisperx",
      "description": {
        "name": "Whisper X",
        "text": "WhisperX provides fast automatic speech recognition (70x realtime with large-v2) with word-level timestamps and speaker diarization.",
        "link": "github.com/bentoml/BentoWhisperX",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/whisperx.png",
        "label": [
          "üëÇ Speech Recognition"
        ]
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "xtts",
      "description": {
        "name": "XTTS",
        "text": "High-performance Deep Learning models for Text2Speech tasks with support for 16 languages and multi-speakers.",
        "link": "github.com/bentoml/BentoXTTS",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/coqui.png",
        "label": [
          "üó£Ô∏è Text-to-Speech"
        ]
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "sentence_transformers",
      "description": {
        "name": "Sentence Transformers",
        "text": "A sentence transformers model, all-MiniLM-L6-v2, that maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search.",
        "link": "github.com/bentoml/BentoSentenceTransformers",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/st.png",
        "label": [
          "üï∏Ô∏è Embedding"
        ]
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "blip_image_captioning",
      "description": {
        "name": "BLIP",
        "text": "BLIP is a model that is able to perform various multi-modal tasks including visual question answering, image-text retrieval (image-text matching), and image captioning.",
        "link": "github.com/bentoml/BentoBlip/tree/main/BLIP2",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/salesforce.jpeg",
        "label": [
          "üëÅÔ∏è Image-to-Text",
          "üï∏Ô∏è Embedding"
        ]
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "clip",
      "description": {
        "name": "CLIP",
        "text": "CLIP (Contrastive Language‚ÄìImage Pre-training) is a machine learning model developed by OpenAI. It is versatile and excels in tasks like zero-shot learning, image classification, and image-text matching without needing specific training for each task.",
        "link": "github.com/bentoml/BentoCLIP",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/openai.png",
        "label": [
          "üï∏Ô∏è Embedding",
          "üç± Multi-Modal"
        ]
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "deepseek-v3-671b",
      "description": {
        "name": "DeepSeek V3 671B",
        "text": "DeepSeek V3 671B developed by DeepSeek and served using vLLM and BentoML. It offers capabilities for streaming and compatibility with OpenAI's API",
        "link": "github.com/bentoml/BentoVLLM/tree/main/deepseek-v3-671b",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/deepseek.png",
        "label": [
          "‚úçÔ∏è Text Generation"
        ]
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "deepseek-r1-671b",
      "description": {
        "name": "DeepSeek R1 671B",
        "text": "DeepSeek R1 671B developed by DeepSeek and served using vLLM and BentoML. It offers capabilities for streaming and compatibility with OpenAI's API",
        "link": "github.com/bentoml/BentoVLLM/tree/main/deepseek-r1-671b",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/deepseek.png",
        "label": [
          "‚úçÔ∏è Text Generation"
        ]
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "deepseek-r1-distill-llama3.3-70b",
      "description": {
        "name": "DeepSeek R1 Distill Llama 3.3 70B",
        "text": "DeepSeek R1 Distill Llama 3.3 70B developed by DeepSeek and served using vLLM and BentoML. It offers capabilities for streaming and compatibility with OpenAI's API",
        "link": "github.com/bentoml/BentoVLLM/tree/main/deepseek-r1-distill-llama3.3-70b",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/deepseek.png",
        "label": [
          "‚úçÔ∏è Text Generation"
        ]
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "deepseek-r1-distill-llama3.1-8b",
      "description": {
        "name": "DeepSeek R1 Distill Llama 3.1 8B",
        "text": "DeepSeek R1 Distill Llama 3.1 8B developed by DeepSeek and served using vLLM and BentoML. It offers capabilities for streaming and compatibility with OpenAI's API",
        "link": "github.com/bentoml/BentoVLLM/tree/main/deepseek-r1-distill-llama3.1-8b",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/deepseek.png",
        "label": [
          "‚úçÔ∏è Text Generation"
        ]
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "gemma3-4b-instruct",
      "description": {
        "name": "Gemma 3 4B Instruct",
        "text": "Gemma 3 4B Instruct developed by Google and served using vLLM and BentoML. It offers capabilities for streaming and compatibility with OpenAI's API",
        "link": "github.com/bentoml/BentoVLLM/tree/main/gemma3-4b-instruct",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/google.png",
        "label": [
          "‚úçÔ∏è Text Generation",
          "üëÅÔ∏è Image-to-Text"
        ]
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "gemma3-1b-instruct",
      "description": {
        "name": "Gemma 3 1B Instruct",
        "text": "Gemma 3 1B Instruct developed by Google and served using vLLM and BentoML. It offers capabilities for streaming and compatibility with OpenAI's API",
        "link": "github.com/bentoml/BentoVLLM/tree/main/gemma3-1b-instruct",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/google.png",
        "label": [
          "‚úçÔ∏è Text Generation"
        ]
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "jamba1.5-mini",
      "description": {
        "name": "Jamba 1.5 Mini",
        "text": "Jamba 1.5 Mini developed by AI21 Lab and served using vLLM and BentoML. It offers capabilities for streaming and compatibility with OpenAI's API",
        "link": "github.com/bentoml/BentoVLLM/tree/main/jamba1.5-mini",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/ai21-lab.png",
        "label": [
          "‚úçÔ∏è Text Generation"
        ]
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "jamba1.5-large",
      "description": {
        "name": "Jamba 1.5 Large",
        "text": "Jamba 1.5 Large developed by AI21 Lab and served using vLLM and BentoML. It offers capabilities for streaming and compatibility with OpenAI's API",
        "link": "github.com/bentoml/BentoVLLM/tree/main/jamba1.5-large",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/ai21-lab.png",
        "label": [
          "‚úçÔ∏è Text Generation"
        ]
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "llama3.1-8b-instruct",
      "description": {
        "name": "Llama 3.1 8B Instruct",
        "text": "Llama 3.1 8B Instruct developed by Meta and served using vLLM and BentoML. It offers capabilities for streaming and compatibility with OpenAI's API",
        "link": "github.com/bentoml/BentoVLLM/tree/main/llama3.1-8b-instruct",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/meta.png",
        "label": [
          "‚úçÔ∏è Text Generation"
        ]
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "llama3.2-3b-instruct",
      "description": {
        "name": "Llama 3.1 3B Instruct",
        "text": "Llama 3.1 3B Instruct developed by Meta and served using vLLM and BentoML. It offers capabilities for streaming and compatibility with OpenAI's API",
        "link": "github.com/bentoml/BentoVLLM/tree/main/llama3.2-3b-instruct",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/meta.png",
        "label": [
          "‚úçÔ∏è Text Generation"
        ]
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "llama3.2-11b-vision-instruct",
      "description": {
        "name": "Llama 3.2 11B Vision Instruct",
        "text": "Llama 3.2 11B Vision Instruct developed by Meta and served using vLLM and BentoML. It offers capabilities for streaming and compatibility with OpenAI's API",
        "link": "github.com/bentoml/BentoVLLM/tree/main/llama3.2-11b-vision-instruct",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/meta.png",
        "label": [
          "‚úçÔ∏è Text Generation",
          "üëÅÔ∏è Image-to-Text"
        ]
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "llama4-17b-maverick-instruct",
      "description": {
        "name": "Llama 4 Maverick 17B-128E Instruct",
        "text": "Llama 4 Maverick 17B-128E Instruct developed by Meta and served using vLLM and BentoML. It offers capabilities for streaming and compatibility with OpenAI's API",
        "link": "github.com/bentoml/BentoVLLM/tree/main/llama4-17b-maverick-instruct",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/meta.png",
        "label": [
          "‚úçÔ∏è Text Generation",
          "üëÅÔ∏è Image-to-Text"
        ]
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "llama4-17b-scout-instruct",
      "description": {
        "name": "Llama 4 Scout 17B-16E Instruct",
        "text": "Llama 4 Scout 17B-16E Instruct developed by Meta and served using vLLM and BentoML. It offers capabilities for streaming and compatibility with OpenAI's API",
        "link": "github.com/bentoml/BentoVLLM/tree/main/llama4-17b-scout-instruct",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/meta.png",
        "label": [
          "‚úçÔ∏è Text Generation",
          "üëÅÔ∏è Image-to-Text"
        ]
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "llama3.3-70b-instruct",
      "description": {
        "name": "Llama 3.3 70B Instruct",
        "text": "Llama 3.3 70B Instruct developed by Meta and served using vLLM and BentoML. It offers capabilities for streaming and compatibility with OpenAI's API",
        "link": "github.com/bentoml/BentoVLLM/tree/main/llama3.3-70b-instruct",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/meta.png",
        "label": [
          "‚úçÔ∏è Text Generation"
        ]
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "pixtral-12b-2409",
      "description": {
        "name": "Pixtral 12B 2409",
        "text": "Pixtral 12B 2409 developed by Mistral AI and served using vLLM and BentoML. It offers capabilities for streaming and compatibility with OpenAI's API",
        "link": "github.com/bentoml/BentoVLLM/tree/main/pixtral-12b-2409",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/mistral-ai.png",
        "label": [
          "‚úçÔ∏è Text Generation",
          "üëÅÔ∏è Image-to-Text"
        ]
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "ministral-8b-instruct-2410",
      "description": {
        "name": "Ministral 8B Instruct 2410",
        "text": "Ministral 8B Instruct 2410 developed by Mistral AI and served using vLLM and BentoML. It offers capabilities for streaming and compatibility with OpenAI's API",
        "link": "github.com/bentoml/BentoVLLM/tree/main/ministral-8b-instruct-2410",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/mistral-ai.png",
        "label": [
          "‚úçÔ∏è Text Generation"
        ]
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "mistral-small-3.1-24b-instruct-2503",
      "description": {
        "name": "Mistral Small 3.1 24B Instruct 2503 with Vision and Reasoning capabilities",
        "text": "Mistral Small 3.1 24B Instruct 2503 with Vision and Reasoning capabilities developed by Mistral AI and served using vLLM and BentoML. It offers capabilities for streaming and compatibility with OpenAI's API",
        "link": "github.com/bentoml/BentoVLLM/tree/main/mistral-small-3.1-24b-instruct-2503",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/mistral-ai.png",
        "label": [
          "‚úçÔ∏è Text Generation",
          "üëÅÔ∏è Image-to-Text"
        ]
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "phi4-14b",
      "description": {
        "name": "Phi 4 14B",
        "text": "Phi 4 14B developed by Microsoft and served using vLLM and BentoML. It offers capabilities for streaming and compatibility with OpenAI's API",
        "link": "github.com/bentoml/BentoVLLM/tree/main/phi4-14b",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/microsoft.png",
        "label": [
          "‚úçÔ∏è Text Generation"
        ]
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "qwen2.5-vl-32b-instruct",
      "description": {
        "name": "Qwen 2.5 VL 32B Instruct",
        "text": "Qwen 2.5 VL 32B Instruct developed by Alibaba and served using vLLM and BentoML. It offers capabilities for streaming and compatibility with OpenAI's API",
        "link": "github.com/bentoml/BentoVLLM/tree/main/qwen2.5-vl-32b-instruct",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/alibaba.png",
        "label": [
          "‚úçÔ∏è Text Generation",
          "üëÅÔ∏è Image-to-Text"
        ]
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "qwq-32b",
      "description": {
        "name": "QWQ 32B",
        "text": "QWQ 32B developed by Alibaba and served using vLLM and BentoML. It offers capabilities for streaming and compatibility with OpenAI's API",
        "link": "github.com/bentoml/BentoVLLM/tree/main/qwq-32b",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/alibaba.png",
        "label": [
          "‚úçÔ∏è Text Generation"
        ]
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "qwen3-8b",
      "description": {
        "name": "Qwen 3 8B",
        "text": "Qwen 3 8B developed by Alibaba and served using vLLM and BentoML. It offers capabilities for streaming and compatibility with OpenAI's API",
        "link": "github.com/bentoml/BentoVLLM/tree/main/qwen3-8b",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/alibaba.png",
        "label": [
          "‚úçÔ∏è Text Generation"
        ]
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "qwen3-30b-a3b",
      "description": {
        "name": "Qwen 3 30B A3B MoE",
        "text": "Qwen 3 30B A3B MoE developed by Alibaba and served using vLLM and BentoML. It offers capabilities for streaming and compatibility with OpenAI's API",
        "link": "github.com/bentoml/BentoVLLM/tree/main/qwen3-30b-A3b",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/alibaba.png",
        "label": [
          "‚úçÔ∏è Text Generation"
        ]
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "qwen3-235b-a22b",
      "description": {
        "name": "Qwen 3 235B A22B MoE",
        "text": "Qwen 3 235B A22B MoE developed by Alibaba and served using vLLM and BentoML. It offers capabilities for streaming and compatibility with OpenAI's API",
        "link": "github.com/bentoml/BentoVLLM/tree/main/qwen3-235b-A22b",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/alibaba.png",
        "label": [
          "‚úçÔ∏è Text Generation"
        ]
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "deepseek-prover-v2-671b",
      "description": {
        "name": "DeepSeek Prover V2 671B",
        "text": "DeepSeek Prover V2 671B developed by DeepSeek and served using vLLM and BentoML. It offers capabilities for streaming and compatibility with OpenAI's API",
        "link": "github.com/bentoml/BentoVLLM/tree/main/deepseek-prover-v2-671b",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/deepseek.png",
        "label": [
          "‚úçÔ∏è Text Generation"
        ]
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "deepseek-prover-v2-7b",
      "description": {
        "name": "DeepSeek Prover V2 7B",
        "text": "DeepSeek Prover V2 7B developed by DeepSeek and served using vLLM and BentoML. It offers capabilities for streaming and compatibility with OpenAI's API",
        "link": "github.com/bentoml/BentoVLLM/tree/main/deepseek-prover-v2-7b",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/deepseek.png",
        "label": [
          "‚úçÔ∏è Text Generation"
        ]
      }
    }
  ]
}
