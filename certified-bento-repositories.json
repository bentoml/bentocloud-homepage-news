{
  "certified_bentos": [
    {
      "org_name": "bentoml",
      "repo_name": "meta-llama--llama-2-13b-hf-service",
      "description": {
        "name": "Llama2 13B",
        "text": "Llama 2 13B parameters large language model developed by Meta and served using vLLM and OpenLLM. It's designed for high throughput and fast inference, offering capabilities for streaming and compatibility with OpenAI's API.",
        "link": "github.com/bentoml/OpenLLM",
        "image": "https://www.bentoml.com/_next/image?url=https%3A%2F%2Fadmin.bentoml.com%2Fuploads%2Fopenllm_45bf9acac5.jpg&w=640&q=75",
        "label": ["‚úçÔ∏è Text Generation"],
        "recommendation_configs": {
          "services": { "llm-llama-runner": { "instance_type": "gpu.a100.1" } }
        }
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "meta-llama--llama-2-7b-hf-service",
      "description": {
        "name": "Llama2 7B",
        "text": "Llama 2 7B parameters large language model developed by Meta and served using vLLM and OpenLLM. It's designed for high throughput and fast inference, offering capabilities for streaming and compatibility with OpenAI's API.",
        "link": "github.com/bentoml/OpenLLM",
        "image": "https://www.bentoml.com/_next/image?url=https%3A%2F%2Fadmin.bentoml.com%2Fuploads%2Fopenllm_45bf9acac5.jpg&w=640&q=75",
        "label": ["‚úçÔ∏è Text Generation"],
        "recommendation_configs": {
          "services": { "llm-llama-runner": { "instance_type": "gpu.l4.1" } }
        }
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "thebloke--mixtral-8x7b-v0.1-gptq-service",
      "description": {
        "name": "OpenLLM Mixtral 8x7B",
        "text": "High quality sparse mixture of experts model (SMoE) developed by Mistral and served using vLLM and OpenLLM. It's designed for high throughput and fast inference, offering capabilities for streaming and compatibility with OpenAI's API.",
        "link": "github.com/bentoml/OpenLLM",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/mixtral8-7b.png",
        "label": ["‚úçÔ∏è Text Generation"],
        "recommendation_configs": {
          "services": { "llm-mixtral-runner": { "instance_type": "gpu.a100.1" } }
        }
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "mistralai--mistral-7b-instruct-v0.2-service",
      "description": {
        "name": "OpenLLM Mistral 7B",
        "text": "Mistral 7B parameters large language model developed by Mistral and served using vLLM and OpenLLM. It's designed for high throughput and fast inference, offering capabilities for streaming and compatibility with OpenAI's API.",
        "link": "github.com/bentoml/OpenLLM",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/mixtral7b.png",
        "label": ["‚úçÔ∏è Text Generation"],
        "recommendation_configs": {
          "services": { "llm-mistral-runner": { "instance_type": "gpu.l4.1" } }
        }
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "vllm",
      "description": {
        "name": "Llama 7B with vLLM",
        "text": "Llama 2 7B parameters large language model developed by Meta, served using the vLLM for state-of-the-art throughput, efficient management of attention key and value memory with PagedAttention, continuous batching of incoming requests, fast model execution with CUDA/HIP graph, quantization, and optimized CUDA kernels.",
        "link": "github.com/bentoml/BentoVLLM",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/vllm.png",
        "label": ["‚úçÔ∏è Text Generation"]
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "control_net",
      "description": {
        "name": "ControlNet",
        "text": "ControlNet is a type of model for controlling image diffusion models by conditioning the model with an additional input image. There are many types of conditioning inputs (canny edge, user sketching, human pose, depth, and more) you can use to control a diffusion model.",
        "link": "github.com/bentoml/BentoControlNet",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/controlnet.png",
        "label": ["üé® Image Generation"]
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "stable_diffusion_video",
      "description": {
        "name": "Stable Diffusion Video",
        "text": "Foundation model for generative video based on the image model Stable Diffusion.",
        "link": "github.com/bentoml/BentoSVD",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/svd.gif",
        "label": ["üé¨ Video Generation"]
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "stable_diffusion2",
      "description": {
        "name": "Stable Diffusion 2",
        "text": "Stable Diffusion is a deep learning, text-to-image model based on diffusion techniques. Stable Diffusion 2.0 delivers several big improvements and features including a new text-to-image diffusion models, super-resolution upscaler diffusion models, depth-to-image diffusion model, and updated inpainting diffusion model.",
        "link": "github.com/bentoml/BentoSD2Upscaler",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/sd2.png",
        "label": ["üé® Image Generation"]
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "sdxl_turbo",
      "description": {
        "name": "SDXL Turbo",
        "text": "SDXL Turbo achieves state-of-the-art performance with a new distillation technology, enabling single-step image generation with unprecedented quality, reducing the required step count from 50 to just one.",
        "link": "github.com/bentoml/BentoSDXLTurbo",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/sdxl.png",
        "label": ["üé® Image Generation"]
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "blip_image_captioning",
      "description": {
        "name": "BLIP",
        "text": "BLIP is a model that is able to perform various multi-modal tasks including visual question answering, image-text retrieval (image-text matching), and image captioning.",
        "link": "github.com/bentoml/BentoBlip",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/blip.png",
        "label": ["üëÅÔ∏è Image-to-Text", "üï∏Ô∏è Embedding"]
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "whisperx",
      "description": {
        "name": "Whisper X",
        "text": "WhisperX provides fast automatic speech recognition (70x realtime with large-v2) with word-level timestamps and speaker diarization.",
        "link": "github.com/bentoml/BentoWhisperX",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/whisperx.png",
        "label": ["üëÇ Speech Recognition"]
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "xtts",
      "description": {
        "name": "XTTS",
        "text": "High-performance Deep Learning models for Text2Speech tasks with support for 16 languages and multi-speakers.",
        "link": "github.com/bentoml/BentoXTTS",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/xtts.png",
        "label": ["üó£Ô∏è Text-to-Speech"]
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "sentence_transformers",
      "description": {
        "name": "Sentence Transformers",
        "text": "A sentence transformers model, all-MiniLM-L6-v2, that maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search.",
        "link": "https://github.com/bentoml/BentoSentenceTransformers",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/st.png",
        "label": ["üï∏Ô∏è Embedding"]
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "latent_consistency",
      "description": {
        "name": "LCM",
        "text": "Latent Consistency Models (LCMs) are able to generate high-quality images in just a few steps, representing a big leap forward because many pipelines require at least 25+ steps.",
        "link": "github.com/bentoml/BentoLCM",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/lcm.png",
        "label": ["üé® Image Generation"]
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "clip",
      "description": {
        "name": "CLIP",
        "text": "CLIP (Contrastive Language‚ÄìImage Pre-training) is a machine learning model developed by OpenAI. It is versatile and excels in tasks like zero-shot learning, image classification, and image-text matching without needing specific training for each task.",
        "link": "github.com/bentoml/BentoCLIP",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/clip.png",
        "label": ["üï∏Ô∏è Embedding", "üç± Multi-Modal"]
      }
    }
  ]
}
