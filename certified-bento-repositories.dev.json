{
  "certified_bentos": [
    {
      "org_name": "bentoml",
      "repo_name": "bentovllm-llama3-70b-insruct-awq-service",
      "description": {
        "name": "Llama3 70B Instruct with AWQ quantization",
        "text": "Llama 3 70B parameters large language model developed by Meta and served using vLLM and BentoML with AWQ quantization. It offers capabilities for streaming and compatibility with OpenAI's API.",
        "link": "github.com/bentoml/BentoVLLM",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/llama3-70b-awq.png",
        "label": ["‚úçÔ∏è Text Generation"]
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "bentovllm-llama3-8b-insruct-service",
      "description": {
        "name": "Llama3 8B Instruct",
        "text": "Llama 3 8B parameters large language model developed by Meta and served using vLLM and BentoML. It's designed for high throughput and fast inference, offering capabilities for streaming and compatibility with OpenAI's API.",
        "link": "github.com/bentoml/BentoVLLM",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/llama3-8b.png",
        "label": ["‚úçÔ∏è Text Generation"]
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "bentovllm-llama2-7b-chat-service",
      "description": {
        "name": "Llama2 7B Chat",
        "text": "Llama 2 7B parameters large language model developed by Meta and served using vLLM and BentoML. It's designed for high throughput and fast inference, offering capabilities for streaming and compatibility with OpenAI's API.",
        "link": "github.com/bentoml/BentoVLLM",
        "image": "https://www.bentoml.com/_next/image?url=https%3A%2F%2Fadmin.bentoml.com%2Fuploads%2Fopenllm_45bf9acac5.jpg&w=640&q=75",
        "label": [
          "‚úçÔ∏è Text Generation"
        ]
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "mixtral-8x7b-instruct-gptq-service",
      "description": {
        "name": "Mixtral 8x7B Instruct",
        "text": "High quality sparse mixture of experts model (SMoE) developed by Mistral and served using vLLM and BentoML. It's designed for high throughput and fast inference, offering capabilities for streaming and compatibility with OpenAI's API.",
        "link": "github.com/bentoml/BentoVLLM",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/mixtral8-7b.png",
        "label": [
          "‚úçÔ∏è Text Generation"
        ]
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "mistral-7b-instruct-service",
      "description": {
        "name": "Mistral 7B Instrut",
        "text": "Mistral 7B parameters large language model developed by Mistral and served using vLLM and BentoML. It's designed for high throughput and fast inference, offering capabilities for streaming and compatibility with OpenAI's API.",
        "link": "github.com/bentoml/BentoVLLM",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/mixtral7b.png",
        "label": [
          "‚úçÔ∏è Text Generation"
        ]
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "bentovllm-solar-instruct-service",
      "description": {
        "name": "Solar 10.7B Instruct",
        "text": "Solar 10.7B parameters large language model developed by Upstage and served using vLLM and BentoML. It's designed for high throughput and fast inference, offering capabilities for streaming and compatibility with OpenAI's API.",
        "link": "github.com/bentoml/BentoVLLM",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/solar10.7b.png",
        "label": [
          "‚úçÔ∏è Text Generation"
        ]
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "control_net",
      "description": {
        "name": "ControlNet",
        "text": "ControlNet is a type of model for controlling image diffusion models by conditioning the model with an additional input image. There are many types of conditioning inputs (canny edge, user sketching, human pose, depth, and more) you can use to control a diffusion model.",
        "link": "github.com/bentoml/BentoControlNet",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/controlnet.png",
        "label": [
          "üé® Image Generation"
        ]
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "stable_diffusion_video",
      "description": {
        "name": "Stable Diffusion Video",
        "text": "Foundation model for generative video based on the image model Stable Diffusion.",
        "link": "github.com/bentoml/BentoSVD",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/svd.gif",
        "label": [
          "üé¨ Video Generation"
        ]
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "stable_diffusion2",
      "description": {
        "name": "Stable Diffusion 2",
        "text": "Stable Diffusion is a deep learning, text-to-image model based on diffusion techniques. Stable Diffusion 2.0 delivers several big improvements and features including a new text-to-image diffusion models, super-resolution upscaler diffusion models, depth-to-image diffusion model, and updated inpainting diffusion model.",
        "link": "github.com/bentoml/BentoSD2Upscaler",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/sd2.png",
        "label": [
          "üé® Image Generation"
        ]
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "sdxl_turbo",
      "description": {
        "name": "SDXL Turbo",
        "text": "SDXL Turbo achieves state-of-the-art performance with a new distillation technology, enabling single-step image generation with unprecedented quality, reducing the required step count from 50 to just one.",
        "link": "github.com/bentoml/BentoSDXLTurbo",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/sdxl.png",
        "label": [
          "üé® Image Generation"
        ]
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "blip_image_captioning",
      "description": {
        "name": "BLIP",
        "text": "BLIP is a model that is able to perform various multi-modal tasks including visual question answering, image-text retrieval (image-text matching), and image captioning.",
        "link": "github.com/bentoml/BentoBlip",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/blip.png",
        "label": [
          "üëÅÔ∏è Image-to-Text",
          "üï∏Ô∏è Embedding"
        ]
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "whisperx",
      "description": {
        "name": "Whisper X",
        "text": "WhisperX provides fast automatic speech recognition (70x realtime with large-v2) with word-level timestamps and speaker diarization.",
        "link": "github.com/bentoml/BentoWhisperX",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/whisperx.png",
        "label": [
          "üëÇ Speech Recognition"
        ]
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "xtts",
      "description": {
        "name": "XTTS",
        "text": "High-performance Deep Learning models for Text2Speech tasks with support for 16 languages and multi-speakers.",
        "link": "github.com/bentoml/BentoXTTS",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/xtts.png",
        "label": [
          "üó£Ô∏è Text-to-Speech"
        ]
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "sentence_transformers",
      "description": {
        "name": "Sentence Transformers",
        "text": "A sentence transformers model, all-MiniLM-L6-v2, that maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search.",
        "link": "github.com/bentoml/BentoSentenceEmbedding",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/st.png",
        "label": [
          "üï∏Ô∏è Embedding"
        ]
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "latent_consistency",
      "description": {
        "name": "LCM",
        "text": "Latent Consistency Models (LCMs) are able to generate high-quality images in just a few steps, representing a big leap forward because many pipelines require at least 25+ steps.",
        "link": "github.com/bentoml/BentoLCM",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/lcm.png",
        "label": [
          "üé® Image Generation"
        ]
      }
    },
    {
      "org_name": "bentoml",
      "repo_name": "clip",
      "description": {
        "name": "CLIP",
        "text": "CLIP (Contrastive Language‚ÄìImage Pre-training) is a machine learning model developed by OpenAI. It is versatile and excels in tasks like zero-shot learning, image classification, and image-text matching without needing specific training for each task.",
        "link": "github.com/bentoml/BentoCLIP",
        "image": "https://raw.githubusercontent.com/bentoml/bentocloud-homepage-news/main/imgs/clip.png",
        "label": [
          "üï∏Ô∏è Embedding"
        ]
      }
    }
  ]
}
